{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "variable-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import inf\n",
    "from utils import *\n",
    "from classifiers.MultivariateGaussianClassifier import *\n",
    "from classifiers.NaiveBayesClassifier import *\n",
    "from classifiers.TiedCovarianceGaussianClassifier import *\n",
    "from classifiers.TiedDiagCovGaussianClassifier import *\n",
    "from classifiers.LogisticRegression import *\n",
    "from classifiers.LinearSVM import *\n",
    "from classifiers.KernelSVM import *\n",
    "from classifiers.GaussianMixtureModel import *\n",
    "from transformers.PCA import *\n",
    "from transformers.Gaussianizer import *\n",
    "from tabulate import tabulate\n",
    "from itertools import combinations\n",
    "import time\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import sklearn.model_selection\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "outdoor-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: 'Not a Pulsar',\n",
    "    1: 'Pulsar'\n",
    "}\n",
    "\n",
    "features_map = {\n",
    "    0: 'Mean of the integrated profile',\n",
    "    1: 'Standard deviation of the integrated profile',\n",
    "    2: 'Excess kurtosis of the integrated profile',\n",
    "    3: 'Skewness of the integrated profile',\n",
    "    4: 'Mean of the DM-SNR curve',\n",
    "    5: 'Standard deviation of the DM-SNR curve',\n",
    "    6: 'Excess kurtosis of the DM-SNR curve',\n",
    "    7: 'Skewness of the DM-SNR curve'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "positive-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    data = []\n",
    "    labels = []\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            fields = line.split(',')\n",
    "            data.append([float(feature) for feature in fields[0: 8]])\n",
    "            labels.append(int(fields[8]))\n",
    "    data = numpy.array(data).T  # transpose to have the features on the rows and the samples on the columns\n",
    "    labels = numpy.array(labels)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "intelligent-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(D, L, folder='hist'):\n",
    "    D_index_L = [D[:, L == i] for i in set(L)]\n",
    "\n",
    "    for i in features_map.keys():\n",
    "        plt.figure()\n",
    "        plt.xlabel(features_map[i])\n",
    "        for index, data in enumerate(D_index_L):\n",
    "            plt.hist(data[i, :], bins=20, density=True, ec='black', alpha=0.5, label=labels_map[index])\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('./plots/' + folder + '/hist_%d.png' % i)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "facial-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(D, L, folder='scatter'):\n",
    "    D_index_L = [D[:, L == i] for i in set(L)]\n",
    "\n",
    "    for i in features_map.keys():\n",
    "        for j in features_map.keys():\n",
    "            if i == j:\n",
    "                continue\n",
    "            plt.figure()\n",
    "            plt.xlabel(features_map[i])\n",
    "            plt.ylabel(features_map[j])\n",
    "            for index, data in enumerate(D_index_L):\n",
    "                plt.scatter(data[i, :], data[j, :], label=labels_map[index], alpha=0.5)  # red\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('./plots/' + folder + '/scatter_%d_%d.png' % (i, j))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "impaired-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(D, folder='heatmap', subtitle='', color='YlGn'):\n",
    "    corr_coef = numpy.corrcoef(D)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(corr_coef, cmap=color)\n",
    "    for i in range(len(features_map)):\n",
    "        for j in range(len(features_map)):\n",
    "            ax.text(j, i, str(round(corr_coef[i, j], 1)), ha=\"center\", va=\"center\", color=\"r\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('./plots/' + folder + '/corr_coeff_' + subtitle + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "signed-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(true, predicted):\n",
    "    K = numpy.unique(numpy.concatenate((true, predicted))).size\n",
    "    confusion_matrix = numpy.zeros((K, K), dtype=numpy.int64)\n",
    "\n",
    "    # for i in range(len(true)):\n",
    "    #     confusion_matrix[predicted[i], true[i]] += 1\n",
    "\n",
    "    # 6 times speed up with respect to the previous code\n",
    "    labels = numpy.hstack((vcol(predicted), vcol(true)))\n",
    "    for indexes in set(combinations(tuple(list(range(K)) + list(range(K))), K)):\n",
    "        equals = numpy.array(labels == indexes, dtype=numpy.int8).sum(axis=1) == K\n",
    "        confusion_matrix[indexes] = numpy.array(equals, dtype=numpy.int8).sum()\n",
    "\n",
    "    return confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "insured-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCFu(prior, cfn, cfp, confusion_matrix):\n",
    "    FNR = confusion_matrix[0, 1] / sum(confusion_matrix[:, 1])\n",
    "    FPR = confusion_matrix[1, 0] / sum(confusion_matrix[:, 0])\n",
    "    DCFu = prior * cfn * FNR + (1 - prior) * cfp * FPR\n",
    "    return DCFu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "native-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCF(prior, cfn, cfp, confusion_matrix):\n",
    "    DCFu_ = DCFu(prior, cfn, cfp, confusion_matrix)\n",
    "    Bdummy = min(prior * cfn, (1 - prior) * cfp)\n",
    "    return DCFu_ / Bdummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "selective-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_DCF(llr, labels, prior, cfn, cfp):\n",
    "    scores = llr  # numpy.sort(llr)  # without sort improve performance\n",
    "\n",
    "    mindcf = None\n",
    "    for i, threshold in enumerate(scores):\n",
    "        predicted = 0 + (llr > threshold)\n",
    "        confusion_matrix_min_dcf = compute_confusion_matrix(labels, predicted)\n",
    "        DCF_ = DCF(prior, cfn, cfp, confusion_matrix_min_dcf)\n",
    "        mindcf = mindcf if mindcf is not None and mindcf <= DCF_ else DCF_\n",
    "\n",
    "    return mindcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "resident-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_min_DCF(D, L, K, Classifier, prior, class_args=(), transformers=[], transf_args=[]):\n",
    "    if K <= 0 or K > D.shape[1]:\n",
    "        raise Exception(\"K-Fold : K should be > 1 and <= \" + str(D.shape[1]))\n",
    "    nTest = int(D.shape[1] / K)\n",
    "    nTrain = D.shape[1] - nTest\n",
    "    numpy.random.seed(0)\n",
    "    idx_1 = numpy.random.permutation(D.shape[1])\n",
    "    # duplicate idx\n",
    "    idx = numpy.concatenate((idx_1, idx_1))\n",
    "\n",
    "    n_classes = len(set(L))\n",
    "    llr = numpy.zeros(D.shape[1])\n",
    "    for i in range(K):\n",
    "        start = i * nTest\n",
    "        idxTrain = idx[start: start + nTrain]\n",
    "        idxTest = idx[start + nTrain: start + nTrain + nTest]\n",
    "\n",
    "        DTR = D[:, idxTrain]\n",
    "        DTE = D[:, idxTest]\n",
    "        LTR = L[idxTrain]\n",
    "        LTE = L[idxTest]\n",
    "\n",
    "        for j, T in enumerate(transformers):\n",
    "            transformer = T().fit(DTR, *transf_args[j])\n",
    "            DTR = transformer.transform(DTR)\n",
    "            DTE = transformer.transform(DTE)\n",
    "\n",
    "        classifier = Classifier(DTR, LTR, *class_args)\n",
    "        llr[idxTest] = classifier.llr(DTE)\n",
    "\n",
    "    mindcf = min_DCF(llr, L, prior, 1, 1)\n",
    "\n",
    "    return mindcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "particular-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussianize(D):\n",
    "    return Gaussianizer().fit(D).transform(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "coral-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTR, LTR = load_data('./data/Train.txt')\n",
    "\n",
    "# DTR, _, LTR, _ = sklearn.model_selection.train_test_split(DTR.T, LTR, train_size=1 / 8, random_state=42)\n",
    "# DTR = DTR.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "terminal-suffering",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_plots = False\n",
    "load_precomputed_data = [False, False, False, False]  # [False, False, False, False]\n",
    "store_computed_data = [True, True, True, True]  # [True, True, True, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "honest-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_precomputed_data[0]:\n",
    "    DTR_G = numpy.load('./data/TrainGAU.npy')\n",
    "else:\n",
    "    DTR_G = Gaussianizer().fit(DTR).transform(DTR)\n",
    "    if store_computed_data[0]:\n",
    "        numpy.save('./data/TrainGAU.npy', DTR_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "built-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "if print_plots:\n",
    "    plot_hist(DTR, LTR)\n",
    "    plot_scatter(DTR, LTR)\n",
    "\n",
    "    plot_hist(DTR_G, LTR, folder='hist_GAU')\n",
    "    plot_scatter(DTR_G, LTR, folder='scatter_GAU')\n",
    "\n",
    "    plot_heatmap(DTR, subtitle='all', color='binary')\n",
    "    plot_heatmap(DTR[:, LTR == 1], subtitle='pulsar', color='Blues')\n",
    "    plot_heatmap(DTR[:, LTR == 0], subtitle='not_pulsar', color='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "# Gaussian Models\n",
    "#######################################################################################\n",
    "\n",
    "classifier_name = numpy.array([\n",
    "    'Full-Cov',\n",
    "    'Diag-Cov',\n",
    "    'Tied Full-Cov',\n",
    "    'Tied Diag-Cov'\n",
    "])\n",
    "classifiers = numpy.array([\n",
    "    MultivariateGaussianClassifier,\n",
    "    NaiveBayesClassifier,\n",
    "    TiedCovarianceGaussianClassifier,\n",
    "    TiedDiagCovGaussianClassifier\n",
    "])\n",
    "\n",
    "priors = numpy.array([0.5, 0.1, 0.9])\n",
    "data = [DTR for i in range(6)]\n",
    "mindcf = numpy.zeros((len(data), classifiers.shape[0], priors.shape[0]))\n",
    "transformers = [\n",
    "    [Gaussianizer],\n",
    "    [PCA, Gaussianizer],\n",
    "    [PCA, Gaussianizer],\n",
    "    [PCA, Gaussianizer],\n",
    "    [],\n",
    "    [PCA]\n",
    "]\n",
    "transf_args = [\n",
    "    [()],\n",
    "    [(7,), ()],\n",
    "    [(6,), ()],\n",
    "    [(5,), ()],\n",
    "    [()],\n",
    "    [(7,)]\n",
    "]\n",
    "\n",
    "if len(data) != len(transformers) or len(transformers) != len(transf_args):\n",
    "    raise Exception(\"Length of data/transformers/transf_args incorrect\")\n",
    "elif classifiers.shape[0] != classifier_name.shape[0]:\n",
    "    raise Exception(\"Length of classifiers/classifier_name incoherent\")\n",
    "\n",
    "if load_precomputed_data[1]:\n",
    "    mindcf = numpy.load('./data/minDCF_GAU_models.npy')\n",
    "\n",
    "results = []\n",
    "for d, D in enumerate(data):\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        if not load_precomputed_data[1]:\n",
    "            for i, c in enumerate(classifiers):\n",
    "                for j, p in enumerate(priors):\n",
    "                    print(classifier_name[i] + \" - prior = \" + str(p) + \" - data id = \" + str(d))\n",
    "                    results.append(executor.submit(k_fold_min_DCF, D, LTR, 5, c, p, (), transformers[d], transf_args[d]))\n",
    "                    # print(\"min_DCF = \" + str(mindcf[i, j]))\n",
    "        for i, r in enumerate(tqdm(results)):\n",
    "            mindcf[numpy.unravel_index(i, mindcf.shape, 'C')] = round(r.result(), 3)\n",
    "        table = numpy.hstack((vcol(classifier_name), mindcf[d]))\n",
    "        print(tabulate(table, headers=[\"\"] + list(priors), tablefmt='fancy_grid'))\n",
    "\n",
    "if not store_computed_data[1]:\n",
    "    numpy.save('./data/minDCF_GAU_models.npy', mindcf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "# Logistic Regression\n",
    "#######################################################################################\n",
    "\n",
    "classifier_name = numpy.array([\n",
    "    'Log Reg',\n",
    "    'Log Reg'\n",
    "])\n",
    "classifiers = numpy.array([\n",
    "    LogisticRegression,\n",
    "    LogisticRegression\n",
    "])\n",
    "transformers = [\n",
    "    [Gaussianizer],\n",
    "    []\n",
    "]\n",
    "transf_args = [\n",
    "    [()],\n",
    "    [()]\n",
    "]\n",
    "data = [DTR for i in range(2)]\n",
    "\n",
    "lamb = numpy.array([10 ** i for i in range(-6, 6)])\n",
    "lamb = numpy.array([numpy.linspace(lamb[i], lamb[i + 1], 2) for i in range(lamb.shape[0] - 1)]).reshape(-1)\n",
    "priors = numpy.array([0.5, 0.1, 0.9])\n",
    "\n",
    "if load_precomputed_data[2]:\n",
    "    mindcf = numpy.load('./data/minDCF_LogReg_lamb.npy')\n",
    "else:\n",
    "    mindcf = numpy.zeros((len(data), classifiers.shape[0], priors.shape[0], lamb.shape[0]))\n",
    "\n",
    "if len(data) != len(transformers) or len(transformers) != len(transf_args):\n",
    "    raise Exception(\"Length of data/transformers/transf_args incoherent\")\n",
    "elif classifiers.shape[0] != classifier_name.shape[0]:\n",
    "    raise Exception(\"Length of classifiers/classifier_name incoherent\")\n",
    "\n",
    "results = []\n",
    "for d, D in enumerate(data):\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        if not load_precomputed_data[2]:\n",
    "            for i, c in enumerate(classifiers):\n",
    "                for j, p in enumerate(priors):\n",
    "                    print(classifier_name[i] + \" - prior = \" + str(p) + \" - data id = \" + str(d))\n",
    "                    for k, l in enumerate(lamb):\n",
    "                        results.append(executor.submit(k_fold_min_DCF, D, LTR, 5, c, p, (l,), transformers[d], transf_args[d]))\n",
    "        for i, r in enumerate(tqdm(results)):\n",
    "            mindcf[numpy.unravel_index(i, mindcf.shape, 'C')] = round(r.result(), 3)\n",
    "        table = numpy.hstack((vcol(classifier_name), mindcf[d].min(axis=2, initial=inf)))\n",
    "        print(tabulate(table, headers=[\"\"] + list(priors), tablefmt='fancy_grid'))\n",
    "\n",
    "if store_computed_data[2]:\n",
    "    numpy.save('./data/minDCF_LogReg_lamb.npy', mindcf)\n",
    "\n",
    "for d in range(len(data)):\n",
    "    for i in range(mindcf[d].shape[0] // 2):\n",
    "        plt.figure()\n",
    "        for j, p in enumerate(priors):\n",
    "            plt.plot(lamb, mindcf[d, i + 1, j], label='minDCF (π = ' + str(p) + ')')\n",
    "        plt.xlabel('λ')\n",
    "        plt.ylabel('min DCF')\n",
    "        plt.legend()\n",
    "        plt.xscale('log')\n",
    "        plt.tight_layout()\n",
    "        name = 'Raw' if i == 0 else 'Gaussianized'\n",
    "        if store_computed_data[2]:\n",
    "            plt.savefig('./plots/mindcf_training/LogReg_lamb_' + str(d) + '_' + str(i) + '.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# Linear SVM\n",
    "##################################################################################\n",
    "\n",
    "classifier_name = numpy.array([\n",
    "    'SVM (no class balancing)',\n",
    "    'SVM (with class balancing)'\n",
    "])\n",
    "classifiers = numpy.array([\n",
    "    LinearSVM,\n",
    "    LinearSVM\n",
    "])\n",
    "transformers = [\n",
    "    [],\n",
    "]\n",
    "transf_args = [\n",
    "    [()],\n",
    "]\n",
    "data = [DTR]\n",
    "\n",
    "Ci = numpy.array([10 ** i for i in range(-3, 3)])\n",
    "priors = numpy.array([0.5, 0.1, 0.9])\n",
    "\n",
    "if load_precomputed_data[3]:\n",
    "    mindcf = numpy.load('./data/minDCF_SVM_C.npy')\n",
    "else:\n",
    "    mindcf = numpy.zeros((len(data), classifiers.shape[0], priors.shape[0], Ci.shape[0]))\n",
    "\n",
    "if len(data) != len(transformers) or len(transformers) != len(transf_args):\n",
    "    raise Exception(\"Length of data/transformers/transf_args incoherent\")\n",
    "elif classifiers.shape[0] != classifier_name.shape[0]:\n",
    "    raise Exception(\"Length of classifiers/classifier_name incoherent\")\n",
    "\n",
    "results = []\n",
    "for d, D in enumerate(data):\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        if not load_precomputed_data[3]:\n",
    "            for i, c in enumerate(classifiers):\n",
    "                for j, p in enumerate(priors):\n",
    "                    print(classifier_name[i] + \" - prior = \" + str(p) + \" - data id = \" + str(d))\n",
    "                    for k, C in enumerate(Ci):\n",
    "                        results.append(\n",
    "                            executor.submit(k_fold_min_DCF, D, LTR, 5, c, p, (1, C, p, None,), transformers[d], transf_args[d]))\n",
    "        for i, r in enumerate(tqdm(results)):\n",
    "            mindcf[numpy.unravel_index(i, mindcf.shape, 'C')] = round(r.result(), 3)\n",
    "        table = numpy.hstack((vcol(classifier_name), mindcf[d].min(axis=2, initial=inf)))\n",
    "        print(tabulate(table, headers=[\"\"] + list(priors), tablefmt='fancy_grid'))\n",
    "\n",
    "if store_computed_data[3]:\n",
    "    numpy.save('./data/minDCF_SVM_C.npy', mindcf)\n",
    "\n",
    "for d in range(len(data)):\n",
    "    for i in range(mindcf[d].shape[0]):\n",
    "        plt.figure()\n",
    "        for j, p in enumerate(priors):\n",
    "            plt.plot(lamb, mindcf[d, i, j], label='minDCF (π = ' + str(p) + ')')\n",
    "        plt.xlabel('λ')\n",
    "        plt.ylabel('min DCF')\n",
    "        plt.legend()\n",
    "        plt.xscale('log')\n",
    "        plt.tight_layout()\n",
    "        if store_computed_data[2]:\n",
    "            plt.savefig('./plots/mindcf_training/SVM_C_' + str(d) + '_' + str(i) + '.png')\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
